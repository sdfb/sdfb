# See http://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# To ban all spiders from the entire site uncomment the next two lines:
# User-agent: *
# Disallow: /

# Commenting out crawl delay not respected by Google, problematic spiders
# User-agent: *
# Disallow:
# Crawl-delay: 60

# Disallow problematic spiders
User-agent: Baiduspider
User-agent: Baiduspider-video
User-agent: Baiduspider-image
Disallow: /
